{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Capstone Project: Manufacturing Equipment Output Prediction with Linear Regression\n",
    "\n",
    "## Problem Statement\n",
    "You are working as a data analyst for a manufacturing company that operates injection molding machines to produce plastic components. The company wants to optimize production efficiency by predicting the hourly output (number of parts produced per hour) based on various machine operating parameters.\n",
    "\n",
    "## Steps Covered:\n",
    "1. Data Loading and Exploration\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Data Preprocessing\n",
    "4. Model Building and Training\n",
    "5. Model Evaluation\n",
    "6. Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('manufacturing_dataset_1000_samples.csv')\n",
    "print(f\"Dataset loaded! Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Target variable distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Parts_Per_Hour'], bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Parts Per Hour')\n",
    "plt.xlabel('Parts Per Hour')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "features = [\n",
    "    'Injection_Temperature', 'Injection_Pressure', 'Cycle_Time',\n",
    "    'Cooling_Time', 'Material_Viscosity', 'Ambient_Temperature',\n",
    "    'Machine_Age', 'Operator_Experience', 'Maintenance_Hours'\n",
    "]\n",
    "target = 'Parts_Per_Hour'\n",
    "\n",
    "# Correlation analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df[features + [target]].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Top correlations with target\n",
    "print(\"Correlations with target:\")\n",
    "print(correlation_matrix[target].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for key features\n",
    "key_features = ['Cycle_Time', 'Injection_Temperature', 'Injection_Pressure', 'Cooling_Time']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    axes[i].scatter(df[feature], df[target], alpha=0.6)\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel(target)\n",
    "    axes[i].set_title(f'{feature} vs {target}')\n",
    "    \n",
    "    # Add trend line\n",
    "    try:\n",
    "        z = np.polyfit(df[feature], df[target], 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_range = np.linspace(df[feature].min(), df[feature].max(), 100)\n",
    "        axes[i].plot(x_range, p(x_range), \"r--\", alpha=0.8)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "df_model = df[features + [target]].copy()\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df_model = df_model.dropna()\n",
    "\n",
    "# Split data\n",
    "X = df_model[features]\n",
    "y = df_model[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build and train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Coefficients: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(y_true, y_pred, dataset_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Performance:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    \n",
    "    return r2, rmse\n",
    "\n",
    "train_r2, train_rmse = evaluate_model(y_train, y_train_pred, \"Training\")\n",
    "test_r2, test_rmse = evaluate_model(y_test, y_test_pred, \"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set\n",
    "ax1.scatter(y_train, y_train_pred, alpha=0.6)\n",
    "ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')\n",
    "ax1.set_xlabel('Actual Parts Per Hour')\n",
    "ax1.set_ylabel('Predicted Parts Per Hour')\n",
    "ax1.set_title(f'Training Set: Actual vs Predicted\\nR² = {train_r2:.4f}')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Testing set\n",
    "ax2.scatter(y_test, y_test_pred, alpha=0.6)\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "ax2.set_xlabel('Actual Parts Per Hour')\n",
    "ax2.set_ylabel('Predicted Parts Per Hour')\n",
    "ax2.set_title(f'Testing Set: Actual vs Predicted\\nR² = {test_r2:.4f}')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coefficient': model.coef_,\n",
    "    'Absolute_Coefficient': np.abs(model.coef_)\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values('Absolute_Coefficient', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (by absolute coefficient):\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Absolute_Coefficient'])\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance in Linear Regression Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Residuals vs predicted\n",
    "ax1.scatter(y_test_pred, residuals, alpha=0.6)\n",
    "ax1.axhline(y=0, color='r', linestyle='--')\n",
    "ax1.set_xlabel('Predicted Parts Per Hour')\n",
    "ax1.set_ylabel('Residuals')\n",
    "ax1.set_title('Residuals vs Predicted Values')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution\n",
    "ax2.hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "ax2.set_xlabel('Residuals')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Residuals')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residuals mean: {residuals.mean():.4f}\")\n",
    "print(f\"Residuals std: {residuals.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manufacturing Insights and Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "1. **Model Performance**: The linear regression model achieved an R² of {test_r2:.4f} on the test set\n",
    "2. **Most Important Features**: Based on coefficient analysis\n",
    "3. **Business Implications**: \n",
    "\n",
    "### Recommendations:\n",
    "1. **Optimize Cycle Time**: Shorter cycle times lead to higher output\n",
    "2. **Temperature Control**: Maintain optimal injection temperatures\n",
    "3. **Pressure Management**: Balance injection pressure for efficiency\n",
    "4. **Maintenance Schedule**: Regular maintenance prevents performance degradation\n",
    "5. **Operator Training**: Experienced operators improve productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for deployment\n",
    "import pickle\n",
    "\n",
    "# Save model and scaler\n",
    "with open('manufacturing_model.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'features': features,\n",
    "        'r2_score': test_r2\n",
    "    }, f)\n",
    "\n",
    "print(\"Model saved as 'manufacturing_model.pkl'\")\n",
    "print(\"Ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
